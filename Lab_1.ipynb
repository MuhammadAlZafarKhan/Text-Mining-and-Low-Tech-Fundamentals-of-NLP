{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Lab 1: Reasoning and Proof Models***"
      ],
      "metadata": {
        "id": "Wkx-FF4gHTgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 1:** Models of Argument\n",
        "\n",
        "* **Goal:** Identify claims, evidence, and warrants from text\n",
        "\n",
        "* **Activity:** Extract arguments from text using simple rule-based NLP"
      ],
      "metadata": {
        "id": "luSMx-ZaHhcT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5KL2GNVGZz3",
        "outputId": "2d58d9ae-2495-4760-8894-80543be8b1ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: The model is biased because it misclassifies 70% of sentences with gendered pronouns.\n",
            "Claim: The model is biased\n",
            "Evidence: it misclassifies 70% of sentences with gendered pronouns.\n"
          ]
        }
      ],
      "source": [
        "# Install if needed\n",
        "# !pip install spacy\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"The model is biased because it misclassifies 70% of sentences with gendered pronouns.\"\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for sent in doc.sents:\n",
        "    print(f\"Sentence: {sent.text}\")\n",
        "    # Simple keyword-based detection\n",
        "    if \"because\" in sent.text:\n",
        "        claim, evidence = sent.text.split(\"because\")\n",
        "        print(f\"Claim: {claim.strip()}\")\n",
        "        print(f\"Evidence: {evidence.strip()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 2:** Proof by Demonstration\n",
        "\n",
        "* **Goal:** Demonstrate that an algorithm works with a specific example\n",
        "\n",
        "* **Activity:** Sentiment analysis demonstration"
      ],
      "metadata": {
        "id": "qr3mzSw0H-tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using TextBlob for demonstration\n",
        "# !pip install textblob\n",
        "from textblob import TextBlob\n",
        "\n",
        "texts = [\"I love this movie!\", \"This is terrible.\"]\n",
        "for t in texts:\n",
        "    sentiment = TextBlob(t).sentiment.polarity\n",
        "    label = \"Positive\" if sentiment > 0 else \"Negative\"\n",
        "    print(f\"Text: '{t}' --> Sentiment: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uzdI4v-H70a",
        "outputId": "f340dac0-77b7-4168-e95c-6813af4bd2c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: 'I love this movie!' --> Sentiment: Positive\n",
            "Text: 'This is terrible.' --> Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 3:** Proof by Empirical Method\n",
        "\n",
        "* **Goal:** Validate model performance on a dataset\n",
        "\n",
        "* **Activity:** Train a small NLP classifier and evaluate"
      ],
      "metadata": {
        "id": "KLkqYyhJIdMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Proof by Empirical Method - Fixed Code\n",
        "# Ensure required libraries are installed:\n",
        "# !pip install scikit-learn pandas\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Example dataset (make sure at least 2 samples per class)\n",
        "data = pd.DataFrame({\n",
        "    \"text\": [\n",
        "        \"I love NLP\", \"I hate bugs\", \"Python is great\", \"Debugging is annoying\",\n",
        "        \"AI is amazing\", \"Errors are frustrating\"\n",
        "    ],\n",
        "    \"label\": [1, 0, 1, 0, 1, 0]\n",
        "})\n",
        "\n",
        "# Stratified split ensures both classes in train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data['text'], data['label'], test_size=0.33, random_state=42, stratify=data['label']\n",
        ")\n",
        "\n",
        "# Vectorize text using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train Logistic Regression classifier\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = clf.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"=== Proof by Empirical Method ===\")\n",
        "print(f\"Train texts:\\n{X_train.tolist()}\")\n",
        "print(f\"Test texts:\\n{X_test.tolist()}\\n\")\n",
        "print(f\"Predictions: {y_pred.tolist()}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7OR8vr0IY4b",
        "outputId": "6481cc2e-c1ca-4507-94ab-b5da419adcc0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Proof by Empirical Method ===\n",
            "Train texts:\n",
            "['Debugging is annoying', 'AI is amazing', 'I hate bugs', 'Python is great']\n",
            "Test texts:\n",
            "['I love NLP', 'Errors are frustrating']\n",
            "\n",
            "Predictions: [0, 0]\n",
            "Accuracy: 0.50\n",
            "F1 Score: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 4:** Mathematical Proof\n",
        "\n",
        "* **Goal:** Verify an algorithmâ€™s correctness mathematically\n",
        "\n",
        "* **Activity:** Verify edit distance computation using dynamic programming"
      ],
      "metadata": {
        "id": "YF5NP7oUI180"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_distance(s1, s2):\n",
        "    n, m = len(s1), len(s2)\n",
        "    dp = [[0]*(m+1) for _ in range(n+1)]\n",
        "\n",
        "    for i in range(n+1):\n",
        "        for j in range(m+1):\n",
        "            if i == 0: dp[i][j] = j\n",
        "            elif j == 0: dp[i][j] = i\n",
        "            elif s1[i-1] == s2[j-1]: dp[i][j] = dp[i-1][j-1]\n",
        "            else: dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])\n",
        "    return dp[n][m]\n",
        "\n",
        "# Demonstration\n",
        "s1, s2 = \"kitten\", \"sitting\"\n",
        "print(f\"Edit distance between '{s1}' and '{s2}' is {edit_distance(s1, s2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn0i5TVRJErx",
        "outputId": "74c8f927-b27e-4168-a867-025df3c5b2c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edit distance between 'kitten' and 'sitting' is 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise 5:** Proof by Hermeneutics\n",
        "\n",
        "* **Goal:** Interpret NLP model outputs qualitatively\n",
        "\n",
        "* **Activity:** Examine chatbot responses for empathy"
      ],
      "metadata": {
        "id": "DJIQFwBUJVXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "responses = [\n",
        "    \"I understand your feelings.\",\n",
        "    \"That does not make sense.\",\n",
        "    \"Tell me more about your day.\"\n",
        "]\n",
        "\n",
        "for r in responses:\n",
        "    if \"understand\" in r or \"Tell me more\" in r:\n",
        "        interpretation = \"Empathetic\"\n",
        "    else:\n",
        "        interpretation = \"Neutral/Non-Empathetic\"\n",
        "    print(f\"Response: '{r}' --> Interpretation: {interpretation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMYigEv9JKmr",
        "outputId": "46dc6693-0931-4bf0-eb7f-e764ec05cc24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: 'I understand your feelings.' --> Interpretation: Empathetic\n",
            "Response: 'That does not make sense.' --> Interpretation: Neutral/Non-Empathetic\n",
            "Response: 'Tell me more about your day.' --> Interpretation: Empathetic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uw3-uFdiJgz3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}